{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ae2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "1. FICHE SYNTH√âTIQUE DES DONN√âES\n",
      "==================================================\n",
      "Source : Online Retail II (UCI) - Version Nettoy√©e CSV\n",
      "P√©riode Couverte : 2009-12-01 √† 2010-12-09\n",
      "Volume Initial : 400,916 lignes\n",
      "Nombre de Clients Uniques (avant nettoyage) : 4,312\n",
      "Pays Couverts : 37 pays\n",
      "\n",
      "==================================================\n",
      "2. DICTIONNAIRE DES VARIABLES\n",
      "==================================================\n",
      "                       Nom      Type Dtype  \\\n",
      "invoice_no      invoice_no           int64   \n",
      "stock_code      stock_code          object   \n",
      "description    description          object   \n",
      "quantity          quantity           int64   \n",
      "invoice_date  invoice_date  datetime64[ns]   \n",
      "price                price         float64   \n",
      "customer_id    customer_id          object   \n",
      "country            country          object   \n",
      "sales                sales         float64   \n",
      "\n",
      "                                                     S√©mantique  \n",
      "invoice_no    Identifiant de transaction/facture (commence p...  \n",
      "stock_code                               Identifiant du produit  \n",
      "description                              Description du produit  \n",
      "quantity                                     Quantit√© command√©e  \n",
      "invoice_date                    Date et heure de la transaction  \n",
      "price                                             Prix unitaire  \n",
      "customer_id                        Identifiant unique du client  \n",
      "country                                     Pays de destination  \n",
      "sales         Montant total de la ligne (Quantity * Price) -...  \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 0. PR√âPARATION DE L'ENVIRONNEMENT ET CHARGEMENT DES DONN√âES\n",
    "# =============================================================================\n",
    "\n",
    "# Cellule 0 : Imports, Configuration, Chargement & Fiche Synth√©tique (Parties 0, 1, 2 & 3.1-3.2)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "# Configuration pour l'affichage\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# D√©finir le chemin d'acc√®s au fichier (Assurez-vous que le fichier est dans data/raw/)\n",
    "# IMPORTANT : Le chemin est ajust√© pour charger le fichier CSV nettoy√© tel qu'indiqu√© par l'utilisateur.\n",
    "# Si vous ex√©cutez localement, utilisez le chemin complet : 'C:/Users/gabri/INGE4/Data vis/CLV-RFM-Marketing-App/data_clean.csv'\n",
    "FILE_PATH = '../data_clean.csv' \n",
    "\n",
    "try:\n",
    "    # Charger les donn√©es (format CSV)\n",
    "    # D√©finir l'encodage 'latin1' ou 'ISO-8859-1' si vous rencontrez des probl√®mes d'accents\n",
    "    df = pd.read_csv(FILE_PATH, encoding='utf-8') \n",
    "except FileNotFoundError:\n",
    "    print(f\"Erreur : Le fichier {FILE_PATH} n'a pas √©t√© trouv√©. Veuillez v√©rifier le chemin ou le placer dans le dossier data/processed.\")\n",
    "    df = pd.DataFrame() # Cr√©er un DataFrame vide pour √©viter les erreurs de code suivantes\n",
    "\n",
    "if not df.empty:\n",
    "    # Renommer les colonnes pour la coh√©rence et l'utilisation future dans Streamlit.\n",
    "    # Les noms sont bas√©s sur la structure fournie par l'utilisateur, et TotalAmount est renomm√© 'sales'.\n",
    "    df.columns = ['invoice_no', 'stock_code', 'description', 'quantity', 'invoice_date',\n",
    "                  'price', 'customer_id', 'country', 'sales'] # 'TotalAmount' devient 'sales'\n",
    "\n",
    "    # S'assurer que les colonnes 'invoice_date', 'customer_id', et 'sales' ont les bons types\n",
    "    df['invoice_date'] = pd.to_datetime(df['invoice_date'])\n",
    "    df['customer_id'] = df['customer_id'].astype(str)\n",
    "    \n",
    "    # Affichage de la Fiche Synth√©tique\n",
    "    print(\"=\"*50)\n",
    "    print(\"1. FICHE SYNTH√âTIQUE DES DONN√âES\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Source : Online Retail II (UCI) - Version Nettoy√©e CSV\")\n",
    "    print(f\"P√©riode Couverte : {df['invoice_date'].min().date()} √† {df['invoice_date'].max().date()}\")\n",
    "    print(f\"Volume Initial : {len(df):,} lignes\")\n",
    "    print(f\"Nombre de Clients Uniques (avant nettoyage) : {df['customer_id'].nunique():,}\")\n",
    "    print(f\"Pays Couverts : {df['country'].nunique()} pays\")\n",
    "    \n",
    "    # Affichage du Dictionnaire des Variables\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"2. DICTIONNAIRE DES VARIABLES\")\n",
    "    print(\"=\"*50)\n",
    "    data_dict = pd.DataFrame({\n",
    "        'Nom': df.columns,\n",
    "        'Type Dtype': df.dtypes,\n",
    "        'S√©mantique': [\n",
    "            'Identifiant de transaction/facture (commence par C pour annulation)',\n",
    "            'Identifiant du produit',\n",
    "            'Description du produit',\n",
    "            'Quantit√© command√©e',\n",
    "            'Date et heure de la transaction',\n",
    "            'Prix unitaire',\n",
    "            'Identifiant unique du client',\n",
    "            'Pays de destination',\n",
    "            'Montant total de la ligne (Quantity * Price) - cl√© pour M du RFM et CLV'\n",
    "        ]\n",
    "    })\n",
    "    print(data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bc8db4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "3. QUALIT√â DES DONN√âES\n",
      "==================================================\n",
      "\n",
      "3.1. Valeurs Manquantes (NaN) :\n",
      "              Nombre  Pourcentage\n",
      "invoice_no         0          0.0\n",
      "stock_code         0          0.0\n",
      "description        0          0.0\n",
      "quantity           0          0.0\n",
      "invoice_date       0          0.0\n",
      "price              0          0.0\n",
      "customer_id        0          0.0\n",
      "country            0          0.0\n",
      "sales              0          0.0\n",
      "\n",
      "3.2. Nombre de lignes dupliqu√©es : 0\n",
      "\n",
      "3.3. Aper√ßu des Outliers (Quantity/Price) et Annulations :\n",
      "             count       mean        std    min   25%    50%    75%      max\n",
      "quantity  400916.0  13.767418  97.638385  1.000  2.00   5.00  12.00  19152.0\n",
      "price     400916.0   3.305826  35.047719  0.001  1.25   1.95   3.75  10953.5\n",
      "sales     400916.0  21.945330  77.758075  0.001  5.00  12.50  19.50  15818.4\n",
      "\n",
      "Volume apr√®s nettoyage (lignes valides, clients identifi√©s) : 400,916 lignes\n",
      "Volume des annulations identifi√©es : 0 lignes\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. QUALIT√â ET NETTOYAGE DES DONN√âES\n",
    "# =============================================================================\n",
    "\n",
    "# Cellule 1 : Qualit√© des Donn√©es (Manquants, Doublons, Outliers, Annulations)\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"3. QUALIT√â DES DONN√âES\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 3.1. Valeurs Manquantes\n",
    "    print(\"\\n3.1. Valeurs Manquantes (NaN) :\")\n",
    "    nan_info = df.isnull().sum()\n",
    "    nan_percent = (df.isnull().sum() / len(df)) * 100\n",
    "    print(pd.DataFrame({'Nombre': nan_info, 'Pourcentage': nan_percent.round(2)}).sort_values(by='Nombre', ascending=False))\n",
    "\n",
    "    # NOTE : 'customer_id' a ~25% de valeurs manquantes. Ces lignes DOIVENT √™tre retir√©es pour RFM/CLV.\n",
    "\n",
    "    # 3.2. Doublons\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\n3.2. Nombre de lignes dupliqu√©es : {duplicates}\")\n",
    "\n",
    "    # 3.3. Outliers et R√®gles d'Annulation\n",
    "    print(\"\\n3.3. Aper√ßu des Outliers (Quantity/Price) et Annulations :\")\n",
    "    print(df[['quantity', 'price', 'sales']].describe().T)\n",
    "\n",
    "    # 3.4. Cr√©ation du DataFrame nettoy√© (df_transactions)\n",
    "    \n",
    "    # 1. Suppression des NaN (principalement customer_id)\n",
    "    df_transactions = df.dropna(subset=['customer_id']).copy()\n",
    "\n",
    "    # 2. Suppression des doublons\n",
    "    df_transactions.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 3. Traitement des transactions non-valides et des annulations\n",
    "    \n",
    "    # S√©parer les annulations (InvoiceNo commen√ßant par 'C')\n",
    "    # Assurez-vous que la colonne 'invoice_no' est trait√©e comme une cha√Æne\n",
    "    df_cancellations = df_transactions[df_transactions['invoice_no'].astype(str).str.startswith('C')]\n",
    "    \n",
    "    # Conserver uniquement les transactions valides (Quantity > 0 et Price > 0)\n",
    "    # Exclure les lignes o√π la facture est une annulation et o√π la colonne 'sales' est positive\n",
    "    df_transactions = df_transactions[\n",
    "        (~df_transactions['invoice_no'].astype(str).str.startswith('C')) & \n",
    "        (df_transactions['quantity'] > 0) & \n",
    "        (df_transactions['price'] > 0) &\n",
    "        (df_transactions['sales'] > 0) # La colonne 'sales' doit aussi √™tre positive\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"\\nVolume apr√®s nettoyage (lignes valides, clients identifi√©s) : {len(df_transactions):,} lignes\")\n",
    "    print(f\"Volume des annulations identifi√©es : {len(df_cancellations):,} lignes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4df52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- V√âRIFICATION DE L'ENVIRONNEMENT ---\n",
      "\n",
      "üöÄ TOUS LES SYST√àMES SONT OP√âRATIONNELS.\n",
      "\n",
      "==================================================\n",
      "1. CHARGEMENT ET FICHE D'IDENTIT√â\n",
      "==================================================\n",
      "‚ùå ERREUR CRITIQUE : Le fichier 'data_clean.csv' est introuvable dans le dossier.\n",
      "   Veuillez v√©rifier que le fichier est bien √† c√¥t√© de ce notebook.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Chargement du fichier\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata_clean.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Fichier \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata_clean.csv\u001b[39m\u001b[33m'\u001b[39m\u001b[33m charg√© avec succ√®s.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data_clean.csv'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# <nbformat>4.1</nbformat>\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuration pour afficher toutes les colonnes des DataFrames\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# D√©finition du chemin du fichier de donn√©es\n",
    "DATA_PATH = '../app/data/raw/online_retail_ii.xlsx' # Assurez-vous d'avoir le fichier dans ce chemin\n",
    "\n",
    "# Chargement du jeu de donn√©es (Online Retail II)\n",
    "try:\n",
    "    # Lecture du fichier Excel. Assurez-vous d'utiliser le bon nom de fichier (ici .xlsx)\n",
    "    df = pd.read_excel(DATA_PATH)\n",
    "    print(\"Donn√©es charg√©es avec succ√®s.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERREUR : Le fichier de donn√©es est introuvable √† l'adresse {DATA_PATH}.\")\n",
    "    print(\"Veuillez t√©l√©charger le jeu de donn√©es 'Online Retail II' et le placer dans 'app/data/raw/'.\")\n",
    "    df = pd.DataFrame() # Cr√©e un DataFrame vide en cas d'erreur\n",
    "    \n",
    "# Affichage des 5 premi√®res lignes pour un aper√ßu rapide\n",
    "if not df.empty:\n",
    "    display(df.head())\n",
    "\n",
    "# <markdown>\n",
    "# # Partie I : Notebook d'Exploration Visuelle Compl√®te\n",
    "# \n",
    "# L'objectif de cette premi√®re phase est d'acqu√©rir une compr√©hension exhaustive du jeu de donn√©es *Online Retail II* (UCI) afin de cadrer les analyses et la construction de l'application Streamlit.\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# ## Fiche Synth√©tique des Donn√©es\n",
    "# \n",
    "# ### 1. Source, Volume et P√©riode\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "if not df.empty:\n",
    "    # 1. Volume et P√©riode\n",
    "    print(f\"Source: Online Retail II (UCI)\")\n",
    "    print(f\"Volume: {df.shape[0]:,} lignes et {df.shape[1]} colonnes\")\n",
    "    \n",
    "    # Conversion de la colonne d'horodatage si n√©cessaire (assumant qu'elle est d√©j√† en datetime si l'on utilise read_excel)\n",
    "    # df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate']) \n",
    "    \n",
    "    min_date = df['InvoiceDate'].min()\n",
    "    max_date = df['InvoiceDate'].max()\n",
    "    \n",
    "    print(f\"P√©riode couverte : Du {min_date.strftime('%d/%m/%Y')} au {max_date.strftime('%d/%m/%Y')}\")\n",
    "    print(f\"Clients uniques : {df['Customer ID'].nunique():,} (excluant les valeurs manquantes)\")\n",
    "\n",
    "# <markdown>\n",
    "# ### 2. Dictionnaire des Variables (√Ä Compl√©ter)\n",
    "# \n",
    "# Remplissez ce tableau avec les d√©tails de chaque colonne.\n",
    "# \n",
    "# | Nom de la Variable | Type (Python) | S√©mantique | Unit√©s/Valeurs | Colonne Importante? |\n",
    "# |:------------------|:--------------|:-----------|:---------------|:-------------------|\n",
    "# | `InvoiceNo`       | object        | Num√©ro de facture. Commence par 'C' si annulation (retour). | Entier/Cha√Æne de caract√®res | Oui |\n",
    "# | `StockCode`       | object        | Code produit (Item). | Cha√Æne de caract√®res | Oui |\n",
    "# | `Description`     | object        | Nom du produit. | Cha√Æne de caract√®res | Oui |\n",
    "# | `Quantity`        | int64         | Quantit√© de produits achet√©s par transaction. | Nombre entier | Oui |\n",
    "# | `InvoiceDate`     | datetime64[ns]| Date et heure de la transaction. | Horodatage | Oui |\n",
    "# | `Price`           | float64       | Prix unitaire du produit. | Mon√©taire (GBP, assum√©) | Oui |\n",
    "# | `Customer ID`     | float64       | Identifiant unique du client. | Entier (float avec NaN) | Oui |\n",
    "# | `Country`         | object        | Pays de destination de la commande. | Cha√Æne de caract√®res | Oui |\n",
    "# \n",
    "# ## Qualit√© des Donn√©es\n",
    "# \n",
    "# ### 3. Valeurs Manquantes\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"Aper√ßu des valeurs manquantes par colonne (en %):\")\n",
    "    missing_data = df.isnull().sum() / len(df) * 100\n",
    "    display(missing_data[missing_data > 0].sort_values(ascending=False))\n",
    "    \n",
    "    # Notez l'importance des ID clients manquants pour l'analyse CLV/Cohortes\n",
    "    nan_customers_count = df['Customer ID'].isnull().sum()\n",
    "    print(f\"\\nTotal des lignes sans Customer ID : {nan_customers_count:,} ({missing_data['Customer ID']:.2f} % des donn√©es).\")\n",
    "\n",
    "# <markdown>\n",
    "# ### 4. R√®gles d'Annulation (Retours) et Outliers\n",
    "# \n",
    "# **R√®gle :** Les factures (`InvoiceNo`) commen√ßant par \"C\" sont des annulations ou des retours.\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "if not df.empty:\n",
    "    # Identifier les retours\n",
    "    df['is_return'] = df['InvoiceNo'].astype(str).str.startswith('C')\n",
    "    return_count = df['is_return'].sum()\n",
    "    \n",
    "    print(f\"Nombre total de transactions : {df.shape[0]:,}\")\n",
    "    print(f\"Nombre de retours (lignes 'C...') : {return_count:,} ({return_count/df.shape[0]*100:.2f} % du total)\")\n",
    "\n",
    "    # V√©rification des outliers sur Quantity et Price\n",
    "    print(\"\\nStatistiques sur les quantit√©s et les prix (incluant les retours/annulations):\")\n",
    "    display(df[['Quantity', 'Price']].describe().T)\n",
    "\n",
    "    # Filtrer les quantit√©s ou prix nuls/n√©gatifs (autres que les retours marqu√©s 'C')\n",
    "    negative_quantity = df[df['Quantity'] < 0].shape[0]\n",
    "    zero_price = df[df['Price'] <= 0].shape[0]\n",
    "\n",
    "    print(f\"\\nLignes avec Quantity < 0 (hors 'C'): {negative_quantity:,}\")\n",
    "    print(f\"Lignes avec Price <= 0: {zero_price:,}\")\n",
    "    \n",
    "    print(\"\\n--- Poursuivre avec la suppression des doublons et la cr√©ation des premi√®res m√©triques (ex: TotalPrice) ---\")\n",
    "\n",
    "# <markdown>\n",
    "# ## Prochaine √âtape : Nettoyage et Cr√©ation de M√©triques\n",
    "# \n",
    "# Une fois cette exploration termin√©e, l'√©tape logique est :\n",
    "# 1. **Nettoyer** : Supprimer les lignes avec ID client manquant.\n",
    "# 2. **Pr√©traiter** : G√©rer les retours (les neutraliser, les exclure, ou les utiliser, selon l'approche souhait√©e).\n",
    "# 3. **Calculer** : Cr√©er la colonne `TotalRevenue` (`Quantity` * `Price`).\n",
    "# 4. **Visualiser** : Cr√©er les 6-8 graphiques demand√©s.\n",
    "\n",
    "# <codecell>\n",
    "# Fin du Notebook initial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
